
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Time series classification and clustering &#8212; Time series analysis with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/vnd.jupyter.widget-state+json">{"state": {"255c85edfa604ec3ae88964dd181da00": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "734da64d233a4d219755b3cad2e60e91": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "21e7de5d5be141c088564bacdaa83098": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_255c85edfa604ec3ae88964dd181da00", "max": 420.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_734da64d233a4d219755b3cad2e60e91", "tabbable": null, "tooltip": null, "value": 420.0}}, "06e80d629f224da6a468fac461d8effd": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1b385a615f404f9199edec7745c20a6f": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "51aa646fe6e74ca78fa20b161d1cbec9": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_06e80d629f224da6a468fac461d8effd", "placeholder": "\u200b", "style": "IPY_MODEL_1b385a615f404f9199edec7745c20a6f", "tabbable": null, "tooltip": null, "value": "Fitting GMMs: 100%"}}, "6b21ad91abd3460c91d2f85549bee23d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2de56eae76d0466e927524b253275a09": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "abda8f29988243abbcff1095bfab69ec": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_6b21ad91abd3460c91d2f85549bee23d", "placeholder": "\u200b", "style": "IPY_MODEL_2de56eae76d0466e927524b253275a09", "tabbable": null, "tooltip": null, "value": " 420/420 [00:04&lt;00:00, 64.42it/s]"}}, "79fb29fb836c492297774bf205c2bec9": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0900a6ab4c4a4a13b970d11c2559b0f3": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_51aa646fe6e74ca78fa20b161d1cbec9", "IPY_MODEL_21e7de5d5be141c088564bacdaa83098", "IPY_MODEL_abda8f29988243abbcff1095bfab69ec"], "layout": "IPY_MODEL_79fb29fb836c492297774bf205c2bec9", "tabbable": null, "tooltip": null}}, "f193f07e7d3e4cb087b961b83b136831": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "64d607b393bb41e0998b760261c0c400": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "1c7fa1139fc94908aab1fd8b33efea37": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_f193f07e7d3e4cb087b961b83b136831", "max": 420.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_64d607b393bb41e0998b760261c0c400", "tabbable": null, "tooltip": null, "value": 420.0}}, "2bf9fe150d9b490ea6c75385603fb558": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "85191e4ad63d41caaaf82f3f9608b71d": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "1651b0d84dae4ec7a0cc9345cab109c4": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_2bf9fe150d9b490ea6c75385603fb558", "placeholder": "\u200b", "style": "IPY_MODEL_85191e4ad63d41caaaf82f3f9608b71d", "tabbable": null, "tooltip": null, "value": "Computing TCK (tr-tr): 100%"}}, "d9887715e70848858cd7f2b482e66049": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c854d9eb33a549b89db6f115991de08b": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "4463fbae4b88456db8c9f60da33c0363": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_d9887715e70848858cd7f2b482e66049", "placeholder": "\u200b", "style": "IPY_MODEL_c854d9eb33a549b89db6f115991de08b", "tabbable": null, "tooltip": null, "value": " 420/420 [00:13&lt;00:00, 26.54it/s]"}}, "ff2d97a568b3441da07078d9ead95c43": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0ecd4990027c4feb8bbe8218b9dac5be": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_1651b0d84dae4ec7a0cc9345cab109c4", "IPY_MODEL_1c7fa1139fc94908aab1fd8b33efea37", "IPY_MODEL_4463fbae4b88456db8c9f60da33c0363"], "layout": "IPY_MODEL_ff2d97a568b3441da07078d9ead95c43", "tabbable": null, "tooltip": null}}, "f03feb0b73364e72b322800c26cf6759": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "dc912de3973d47ce828a2997b775b516": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "1b700dc429e24cb6a562a88ef31f5561": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_f03feb0b73364e72b322800c26cf6759", "max": 420.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_dc912de3973d47ce828a2997b775b516", "tabbable": null, "tooltip": null, "value": 420.0}}, "5837e691397641a0a0110db7269fd0ac": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "49dfda7429a24b989a0aed3035edb38e": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "260b875663694421b53ba077625b98a4": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_5837e691397641a0a0110db7269fd0ac", "placeholder": "\u200b", "style": "IPY_MODEL_49dfda7429a24b989a0aed3035edb38e", "tabbable": null, "tooltip": null, "value": "Computing TCK (tr-te): 100%"}}, "3572c4375966400d8291c8e65ac8334c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "123e8b65fcec417bb9ff1cdebdd17b2f": {"model_name": "HTMLStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "background": null, "description_width": "", "font_size": null, "text_color": null}}, "3045dc5511f84dccb3cdc882c8cd16e6": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HTMLView", "description": "", "description_allow_html": false, "layout": "IPY_MODEL_3572c4375966400d8291c8e65ac8334c", "placeholder": "\u200b", "style": "IPY_MODEL_123e8b65fcec417bb9ff1cdebdd17b2f", "tabbable": null, "tooltip": null, "value": " 420/420 [00:15&lt;00:00, 25.65it/s]"}}, "42a69115366e4f4186168980eb72d7b2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "dc2dc27ba8384e6bb743fcee181d9657": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_260b875663694421b53ba077625b98a4", "IPY_MODEL_1b700dc429e24cb6a562a88ef31f5561", "IPY_MODEL_3045dc5511f84dccb3cdc882c8cd16e6"], "layout": "IPY_MODEL_42a69115366e4f4186168980eb72d7b2", "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/12/classification-clustering';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Resources" href="../00/resources.html" />
    <link rel="prev" title="Nonlinear time series analysis" href="../11/nonlinear-ts.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../00/intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Time series analysis with Python - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Time series analysis with Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../00/intro.html">
                    Time series analysis with Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01/introduction_to_time_series.html">Introduction to time series analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02/stationarity.html">Stationarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03/smoothing.html">Smoothing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04/ar-ma.html">AR-MA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05/arma_arima_sarima.html">ARMA, ARIMA, SARIMA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06/unit-root-hurst.html">Unit root test and Hurst exponent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07/kalman-filter.html">Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08/signal-transforms-filters.html">Signal transforms and filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09/prophet.html">Prophet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10/nn-reservoir-computing.html">Neural networks and Reservoir Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11/nonlinear-ts.html">Nonlinear time series analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Time series classification and clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00/resources.html">Resources</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/FilippoMB/python-time-series-handbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/FilippoMB/python-time-series-handbook/issues/new?title=Issue%20on%20page%20%2Fnotebooks/12/classification-clustering.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/12/classification-clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Time series classification and clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-and-clustering">Classification and clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-and-dissimilarity-measures">Similarity and dissimilarity measures</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dissimilarity-measures">Dissimilarity measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-measures">Similarity measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-and-non-linear-measures">Linear and non-linear measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-classification">Effect on Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-clustering">Effect on Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-similarity">Time series similarity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-time-series-mts">Multivariate Time Series (MTS)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alignment-based-metric-dynamic-time-warping-dtw">Alignment-based metric – Dynamic Time Warping (DTW)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-algorithm">DTW algorithm</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-the-optimal-path">Finding the optimal path</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-properties">DTW properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-example">DTW example</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-dtw">Classification with DTW</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nn-classifier"><span class="math notranslate nohighlight">\(k\)</span>-NN classifier</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-with-dtw">Clustering with DTW</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-through-dimensionality-reduction">Visualization through dimensionality reduction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-kernels">Time-series kernels</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm">GMM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-for-time-series-with-missing-data">GMM for time series with missing data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">Ensemble learning</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-tck">Classification with TCK</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-embedding">Time-series embedding</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rc-framework">RC framework</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reservoir-module">Reservoir module</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-module-optional">Dimensionality reduction module (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#representation-module">Representation module</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#readout-module">Readout module</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-rc-embeddings">Classification with RC embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-with-rc-embeddings">Clustering with RC embeddings</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1">Exercise 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2">Exercise 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3">Exercise 3</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="time-series-classification-and-clustering">
<h1>Time series classification and clustering<a class="headerlink" href="#time-series-classification-and-clustering" title="Link to this heading">#</a></h1>
<img alt="../../_images/cover11.png" src="../../_images/cover11.png" />
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p>In this lecture we will cover the following topics:</p>
<ul class="simple">
<li><p>Introduction to classification and clustering.</p></li>
<li><p>Similarity and dissimilarity measures and their impact in classification and clustering.</p></li>
<li><p>Similarity measures for time series.</p></li>
<li><p>Classification and clustering of time series.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span><span class="p">,</span> <span class="n">cosine_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">v_measure_score</span><span class="p">,</span> <span class="n">pairwise_kernels</span><span class="p">,</span> <span class="n">pairwise_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">KernelPCA</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">fcluster</span>
<span class="kn">import</span> <span class="nn">scipy.spatial.distance</span> <span class="k">as</span> <span class="nn">ssd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">dtaidistance</span> <span class="kn">import</span> <span class="n">dtw</span><span class="p">,</span> <span class="n">dtw_ndim</span>
<span class="kn">from</span> <span class="nn">dtaidistance</span> <span class="kn">import</span> <span class="n">dtw_visualisation</span> <span class="k">as</span> <span class="n">dtwvis</span>
<span class="kn">from</span> <span class="nn">tck.TCK</span> <span class="kn">import</span> <span class="n">TCK</span>
<span class="kn">from</span> <span class="nn">tck.datasets</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">reservoir_computing.reservoir</span> <span class="kn">import</span> <span class="n">Reservoir</span>
<span class="kn">from</span> <span class="nn">reservoir_computing.tensorPCA</span> <span class="kn">import</span> <span class="n">tensorPCA</span>
<span class="kn">from</span> <span class="nn">reservoir_computing.modules</span> <span class="kn">import</span> <span class="n">RC_model</span>
<span class="kn">from</span> <span class="nn">reservoir_computing.utils</span> <span class="kn">import</span> <span class="n">compute_test_scores</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="classification-and-clustering">
<h2>Classification and clustering<a class="headerlink" href="#classification-and-clustering" title="Link to this heading">#</a></h2>
<p><strong>Classification</strong></p>
<ul class="simple">
<li><p>Is a <em>supervised</em> task: a classifier uses external supervision to learn a task.</p></li>
<li><p>The supervision usually consists of class information (labels).</p></li>
<li><p>A classifier fits its parameters to predict the correct label.</p></li>
<li><p>This can be seen as learning where to put a decision boundary that separates the classes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate some toy data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="o">-</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">1.7</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_class_example</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">h</span> <span class="o">=</span> <span class="mf">.01</span>  <span class="c1"># step size in the mesh</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> 
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>

    <span class="c1"># Plot the decision boundary. For that, we will assign a color to each point in the mesh [x_min, m_max]x[y_min, y_max].</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<ul class="simple">
<li><p>Most classifiers trade an accurate fit of the training data with generalization capabilities on out-of-sample data.</p></li>
<li><p>The behavior is controlled by hyperparameters that are set through a validation procedure (and usually some experience).</p></li>
<li><p>In this lecture we use <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html">SVC</a>, which is a <a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machine (SVM)</a> for classification.</p></li>
<li><p>Try setting <code class="docutils literal notranslate"><span class="pre">gamma=20</span></code> in the example below to fit the training data better.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_class_example</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/6407499f7ef208b324ee5202ba5ef82c664f58f9739b7dd863af8e78cd835ded.png" src="../../_images/6407499f7ef208b324ee5202ba5ef82c664f58f9739b7dd863af8e78cd835ded.png" />
</div>
</div>
<p><strong>Clustering</strong></p>
<ul class="simple">
<li><p>Is an <em>unsupervised</em> task.</p></li>
<li><p>It only looks at the structure of the data without using additonal information (class labels, extra data, human knowledge, etc..).</p></li>
<li><p>A clustering algorihtm groups data together so that each group is compact and separated from the others.</p></li>
<li><p>Clustering gives insights about the structure of the data.</p></li>
<li><p>The number of clutsers is often not given.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_cluster_example</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>    
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">clust_lab</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centers</span><span class="p">):</span>
            <span class="n">class_inds</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">clust_lab</span><span class="o">==</span><span class="n">ind</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">max_dist</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pairwise_distances</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">class_inds</span><span class="p">]))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Circle</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">max_dist</span><span class="o">*</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s2"> Clutsers&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<ul class="simple">
<li><p>Setting the hyperparameters of clustering algorithms (and unsupervised approaches in general) is more critical than in supervised models.</p></li>
<li><p>Differently from classification, there is not an <em>optimal</em> hyperparameter configuration.</p></li>
<li><p>Here, we use the popular <span class="math notranslate nohighlight">\(k\)</span>-means algorithm.</p></li>
<li><p>Try changing the number of clusters to <code class="docutils literal notranslate"><span class="pre">K=3</span></code> and <code class="docutils literal notranslate"><span class="pre">K=4</span></code> in the code below.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We use the same data (X) as before, but not the labels (y)</span>
<span class="n">plot_cluster_example</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/3dbe1eb30b9f6cfb2f35c7dee818f820ead742a5f3c9726d78069ffc174cdd68.png" src="../../_images/3dbe1eb30b9f6cfb2f35c7dee818f820ead742a5f3c9726d78069ffc174cdd68.png" />
</div>
</div>
<section id="performance-metrics">
<h3>Performance metrics<a class="headerlink" href="#performance-metrics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>There are many metrics to evaluate the performance in classification and clustering tasks.</p></li>
<li><p>The most useful ones to use depend on the problem at hand.</p></li>
<li><p>Often more metrics should be considered at once.</p></li>
<li><p>In this lecture we only consider:</p>
<ul>
<li><p>accuracy and F1 score for classification,</p></li>
<li><p>NMI for clustering.</p></li>
</ul>
</li>
</ul>
<section id="classification">
<h4>Classification<a class="headerlink" href="#classification" title="Link to this heading">#</a></h4>
<p><strong>Accuracy</strong></p>
<ul class="simple">
<li><p>Classification accuracy is the simplest way to measure of how well a classification model performs.</p></li>
<li><p>It’s the ratio of correctly predicted observations to the total observations.</p></li>
<li><p>Is defined as:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}} =\frac{TP + TN}{TP + TN + FN +FP}\]</div>
<ul class="simple">
<li><p>Here, <span class="math notranslate nohighlight">\(TP\)</span> true positives, <span class="math notranslate nohighlight">\(TN\)</span> true negative, <span class="math notranslate nohighlight">\(FP\)</span> false positives, and <span class="math notranslate nohighlight">\(FN\)</span> false negatives.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the data in training and test set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Compute predictions and accuracy</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.99
</pre></div>
</div>
</div>
</div>
<p><strong>F1 Score</strong></p>
<ul class="simple">
<li><p>The F1 Score is the harmonic mean of precision and recall, providing a balance between them.</p></li>
<li><p>It’s used when the class distribution is uneven and you need a measure that takes both <span class="math notranslate nohighlight">\(FP\)</span> and <span class="math notranslate nohighlight">\(FN\)</span> into account.</p></li>
<li><p>Is defined as:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\]</div>
<ul class="simple">
<li><p>where</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{Precision} = \frac{TP}{TP + FP}\]</div>
<ul class="simple">
<li><p>and</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{Recall} = \frac{TP}{TP + FN}\]</div>
<img alt="../../_images/precision-recall.png" src="../../_images/precision-recall.png" />
<div style="text-align: center; font-size: 80%">Image: <a href="https://en.wikipedia.org/wiki/Precision_and_recall">Wikipedia</a></div><p>Let’s create an imbalanced dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_1</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># Samples of class 0</span>
<span class="n">n_samples_2</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Samples of class 1</span>

<span class="n">X_imb</span><span class="p">,</span> <span class="n">y_imb</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="p">[</span><span class="n">n_samples_1</span><span class="p">,</span> <span class="n">n_samples_2</span><span class="p">],</span>
    <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]],</span>
    <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the data in training and test set</span>
<span class="n">X_tr_imb</span><span class="p">,</span> <span class="n">X_te_imb</span><span class="p">,</span> <span class="n">y_tr_imb</span><span class="p">,</span> <span class="n">y_te_imb</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_imb</span><span class="p">,</span> <span class="n">y_imb</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Fit the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mi">20</span><span class="p">})</span> <span class="c1"># Try setting class_weight={1: 20}</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_tr_imb</span><span class="p">,</span> <span class="n">y_tr_imb</span><span class="p">)</span>

<span class="c1"># Compute predictions and accuracy</span>
<span class="n">y_pred_imb</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_te_imb</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_te_imb</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_imb</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.89
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The accuracy score is very high… but are we doing well here?</p></li>
<li><p>If we look closely, the classifier simply assigned all labels to the majority class.</p></li>
<li><p>This is non acceptable in cases where the minority class is of interest.</p></li>
<li><p>For example in anomaly detection.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions of class 0: </span><span class="si">{</span><span class="p">(</span><span class="n">y_pred_imb</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">, predictions of class 1: </span><span class="si">{</span><span class="p">(</span><span class="n">y_pred_imb</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 score: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_te_imb</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_imb</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictions of class 0: 355, predictions of class 1: 65
F1 score: 0.45
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering">
<h4>Clustering<a class="headerlink" href="#clustering" title="Link to this heading">#</a></h4>
<p><strong>Normalized Mutual Information (NMI)</strong></p>
<ul class="simple">
<li><p>NMI is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation).</p></li>
<li><p>It measures the agreement between the cluster assignments, <span class="math notranslate nohighlight">\(C\)</span>, and the class labels <span class="math notranslate nohighlight">\(Y\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{NMI}(C, Y) = \frac{2 \times I(C; Y)}{H(C) + H(Y)}\]</div>
<ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(I(C; Y)\)</span> is the mutual information between cluster and labels, and <span class="math notranslate nohighlight">\(H(C)\)</span> and <span class="math notranslate nohighlight">\(H(Y)\)</span> are the entropies of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, respectively.</p></li>
<li><p>Note that the class labels are not used to form clusters but only to evaluate the results.</p></li>
<li><p>If class labels are not available, one can still form clusters but not compute the NMI.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># NMI for k-means with different values of k</span>
<span class="n">clust_lab</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">labels_</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K=2, NMI: </span><span class="si">{</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">clust_lab</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">clust_lab</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">labels_</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K=3, NMI: </span><span class="si">{</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">clust_lab</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">clust_lab</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">labels_</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K=4, NMI: </span><span class="si">{</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">clust_lab</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K=2, NMI: 0.73
K=3, NMI: 0.92
K=4, NMI: 0.84
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<hr class="docutils" />
<section id="similarity-and-dissimilarity-measures">
<h2>Similarity and dissimilarity measures<a class="headerlink" href="#similarity-and-dissimilarity-measures" title="Link to this heading">#</a></h2>
<section id="dissimilarity-measures">
<h3>Dissimilarity measures<a class="headerlink" href="#dissimilarity-measures" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Quantify how different two objects are: the higher, the more different they are.</p></li>
<li><p>Dissimilarity measures are crucial to distinguish between distinct groups of data or identify outliers.</p></li>
<li><p>The most common linear dissimilarity measure is the Euclidean distance:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[d(\mathbf{x}, \mathbf{y}) = \| \mathbf{x} - \mathbf{y} \|_2\]</div>
<ul class="simple">
<li><p>Also important is the Mahalanobis distance:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[d(\mathbf{x}, \mathbf{y}) = \sqrt{(\mathbf{x} - \mathbf{y})^\top \Sigma^{-1}(\mathbf{x} - \mathbf{y})}\]</div>
<ul class="simple">
<li><p>which reduces to the Euclidean distance when the covariance matrix is <span class="math notranslate nohighlight">\(\Sigma^{-1}=\mathbf{I}\)</span>.</p></li>
</ul>
</section>
<section id="similarity-measures">
<h3>Similarity measures<a class="headerlink" href="#similarity-measures" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A similarity measure quantifies how similar two objects are: the higher the value, the more similar the objects.</p></li>
<li><p>These measures are essential in algorithms that rely on the concept of <em>closeness</em> or <em>similarity</em> to make decisions, such as recommender systems.</p></li>
<li><p>An example of similarity measures is the cosine similarity:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[s(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x}^\top \mathbf{y}}{\|\mathbf{x}|\ \| \mathbf{y}\|}\]</div>
<ul class="simple">
<li><p>Another example is the Pearson correlation coefficient, used in statistics to measure the linear correlation between two variables:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[s(\mathbf{x}, \mathbf{y}) = \frac{\text{cov}(\mathbf{x}, \mathbf{y})}{\sigma_\mathbf{x}, \sigma_\mathbf{y}}\]</div>
</section>
<section id="linear-and-non-linear-measures">
<h3>Linear and non-linear measures<a class="headerlink" href="#linear-and-non-linear-measures" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The measures we described so far are <em>linear</em>.</p></li>
<li><p>It means that their computation follows a linear relationship with respect to the data.</p></li>
<li><p>Some measures, instead, are <em>non-linear</em>, meaning the relationship between the measure and the data does not follow a straight line.</p></li>
<li><p><strong>Kernels</strong> are examples of non-linear similarity measures.</p></li>
<li><p>The most famous kernel is the Radial Basis Function (RBF):</p></li>
</ul>
<div class="math notranslate nohighlight">
\[s(\mathbf{x}, \mathbf{y}) = \text{exp}\left( -\gamma \| \mathbf{x} - \mathbf{y} \|^2 \right)\]</div>
<ul class="simple">
<li><p>The parameter <span class="math notranslate nohighlight">\(\gamma\)</span> is the <em>kernel width</em>, which controls the std. dev. of the Gaussian.</p></li>
<li><p>Setting it properly is crucial for defining distances: smaller values will account for relationshiops between distant objects.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">gamma_vals</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">gamma_vals</span><span class="p">:</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">values</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">similarity</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$\gamma$ = </span><span class="si">{</span><span class="n">gamma</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Distance: $\|\mathbf</span><span class="si">{x}</span><span class="s1"> - \mathbf</span><span class="si">{y}</span><span class="s1">\|^2$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Similarity: $\exp(-\gamma\|\mathbf</span><span class="si">{x}</span><span class="s1"> - \mathbf</span><span class="si">{y}</span><span class="s1">\|^2)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/60ac726c9d98150930a6e4b6aa709dfec4cd33fabb68656a2da77f18c3474d72.png" src="../../_images/60ac726c9d98150930a6e4b6aa709dfec4cd33fabb68656a2da77f18c3474d72.png" />
</div>
</div>
<ul class="simple">
<li><p>The choice of similarity or dissimilarity measure is critical in classification and clustering problems.</p></li>
<li><p>The measure directly affects how well an algorithm can identify the structure of the data.</p></li>
<li><p>An inappropriate choice might lead to poor classification or clustering performance because the measure may not capture the actual relationships among data points.</p></li>
</ul>
</section>
<section id="effect-on-classification">
<h3>Effect on Classification<a class="headerlink" href="#effect-on-classification" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>In the following we generate some toy data and compute a similarity matrix using a linear and nonlinear measure.</p></li>
<li><p>As linear measure, we will use the cosine similarity.</p></li>
<li><p>As non-linear measure we will use an RBF kernel.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_circles</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span> <span class="c1"># Create toy data</span>
<span class="n">X_train</span> <span class="p">,</span> <span class="n">X_test</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#Train-test split</span>

<span class="c1"># Cosine similarity matrix</span>
<span class="n">cosine_train</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># RBF similarity matrix</span>
<span class="n">rbf_kernel_train</span> <span class="o">=</span> <span class="n">pairwise_kernels</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the data</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">))</span>
<span class="n">cm_bright</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">([</span><span class="s2">&quot;#FF0000&quot;</span><span class="p">,</span> <span class="s2">&quot;#0000FF&quot;</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Input data&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>

<span class="c1"># Plot the cosine matrix</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cosine_train</span><span class="p">[</span><span class="n">idx</span><span class="p">][:,</span> <span class="n">idx</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Cosine similarity matrix (linear)&quot;</span><span class="p">)</span>

<span class="c1"># Plot the RBF matrix</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rbf_kernel_train</span><span class="p">[</span><span class="n">idx</span><span class="p">][:,</span> <span class="n">idx</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;RBF kernel matrix (nonlinear)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/b475ede749b3f7cea55c5085bff4b2c7e46a8e79aab4d74c01053ae256cd1636.png" src="../../_images/b475ede749b3f7cea55c5085bff4b2c7e46a8e79aab4d74c01053ae256cd1636.png" />
</div>
</div>
<ul class="simple">
<li><p>We see that the two classes appear more separated when using a nonlinear similarity.</p></li>
</ul>
<ul class="simple">
<li><p>Next, we will train an SVM classifier that uses these two similarity measures.</p></li>
<li><p>We will look at the decision boundaries learned by the classifier and compute its performance on the test data.</p></li>
<li><p>For the RBF kernel, we will use both <span class="math notranslate nohighlight">\(\gamma=0.5\)</span> and <span class="math notranslate nohighlight">\(\gamma=0.1\)</span>.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Linear SVM&quot;</span><span class="p">,</span> <span class="s2">&quot;RBF SVM ($\gamma=0.5$)&quot;</span><span class="p">,</span> <span class="s2">&quot;RBF SVM ($\gamma=0.1$)&quot;</span><span class="p">]</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">classifiers</span><span class="p">)):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm_bright</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot; - Test acc: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/1b29e21b902e61c76edff9d35e3247c4f5e517ff8d2b5204f7c71c10fa4b45aa.png" src="../../_images/1b29e21b902e61c76edff9d35e3247c4f5e517ff8d2b5204f7c71c10fa4b45aa.png" />
</div>
</div>
<ul class="simple">
<li><p>Also in this case, the impact in using different similarity measures is quite big.</p></li>
</ul>
<section id="effect-on-clustering">
<h4>Effect on Clustering<a class="headerlink" href="#effect-on-clustering" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Being clustering an unsupervised task the impact of the (dis)similarity measures is even larger.</p></li>
<li><p>The lack of training cannot compensate for the effect of choosing a bad (dis)similarity.</p></li>
<li><p>Samples get grouped very differently based on what makes them (dis)similar.</p></li>
</ul>
<ul class="simple">
<li><p>In the next example, we look at <em>hierarchical clustering</em> (HC).</p></li>
<li><p>The idea of HC is to progressively form clusters by grouping together samples within a certain distance radius.</p></li>
<li><p>In the beginning, the radius is very small and many distinct clusters are formed.</p></li>
<li><p>As the radius increases, further points are grouped together and the number of clusters decreases.</p></li>
</ul>
<ul class="simple">
<li><p>Let us consider the following data and compute a squared Euclidean distance matrix.</p></li>
<li><p>As HC algorithm we will use the <em>Ward Linkage</em>, which gradually aggregate clusters by optimizing the <a class="reference external" href="https://en.wikipedia.org/wiki/Ward%27s_method#The_minimum_variance_criterion">minimum variance criterion</a>.</p>
<ul>
<li><p>At each step it finds the pair of clusters that leads to minimum increase in total within-cluster variance after merging.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                           <span class="n">cluster_std</span><span class="o">=</span><span class="p">[</span><span class="mf">1.7</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># Normalizing the data facilitates setting the radius</span>

<span class="c1"># Compute the distance matrix</span>
<span class="n">Dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
<span class="n">distArray</span> <span class="o">=</span> <span class="n">ssd</span><span class="o">.</span><span class="n">squareform</span><span class="p">(</span><span class="n">Dist</span><span class="p">)</span>

<span class="c1"># Compute the hierarchy of clusters</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">distArray</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>By setting a different radius (threshold) we obtain different partitions.</p></li>
<li><p>Let’s try as thresholds <code class="docutils literal notranslate"><span class="pre">t=10</span></code> and <code class="docutils literal notranslate"><span class="pre">t=30</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition_1</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Partition 1: </span><span class="si">%d</span><span class="s2"> clusters&quot;</span><span class="o">%</span><span class="k">len</span>(np.unique(partition_1)))

<span class="n">partition_2</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Partition 1: </span><span class="si">%d</span><span class="s2"> clusters&quot;</span><span class="o">%</span><span class="k">len</span>(np.unique(partition_2)))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Partition 1: 8 clusters
Partition 1: 4 clusters
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_clusters</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span> <span class="k">if</span> <span class="n">clusters</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">clusters</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;threshold = 10&quot;</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="n">partition_1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;threshold = 30&quot;</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="n">partition_2</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1e62eb46eaab5264a5a38864259591da0c1db9858ea0c782be7938eb5d705fe7.png" src="../../_images/1e62eb46eaab5264a5a38864259591da0c1db9858ea0c782be7938eb5d705fe7.png" />
</div>
</div>
<ul class="simple">
<li><p>It is possible to visualize the hierarchy generated by HC.</p></li>
<li><p>It is also possible to color the branches based on the threshold value.</p></li>
<li><p>This is a very useful tool to examine the structure in the data at different resolutions.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">above_threshold_color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> 
                <span class="n">show_leaf_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/db574ac3b5bd32d7c4b3a7dfaf9271ae103a30f1a2bdba1faaa1413a3664dcdb.png" src="../../_images/db574ac3b5bd32d7c4b3a7dfaf9271ae103a30f1a2bdba1faaa1413a3664dcdb.png" />
</div>
</div>
<ul class="simple">
<li><p>Partitions that persist for broad ranges of values of the threshold are those that characterize the dataset the most.</p></li>
</ul>
<ul class="simple">
<li><p>Finally, let’s see the effect of using different distance metrics.</p></li>
<li><p>We will use an RBF kernel as before and a Mahalanobis distance that weights each feature differently.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the RBF (note that we must convert it to a distance)</span>
<span class="n">rbf_kernel</span> <span class="o">=</span> <span class="n">pairwise_kernels</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span> <span class="c1"># compute the rbf similarity</span>
<span class="n">rbf_kernel</span> <span class="o">=</span> <span class="n">rbf_kernel</span> <span class="o">+</span> <span class="n">rbf_kernel</span><span class="o">.</span><span class="n">T</span> <span class="c1"># make symmetric</span>
<span class="n">rbf_kernel</span> <span class="o">/=</span> <span class="n">rbf_kernel</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="c1"># normalize to [0, 1]</span>
<span class="n">rbf_dist</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">rbf_kernel</span> <span class="c1"># convert to distance</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">rbf_dist</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># due to numerical errors, the diagonal might not be 0</span>

<span class="c1"># Compute the partition</span>
<span class="n">distArray</span> <span class="o">=</span> <span class="n">ssd</span><span class="o">.</span><span class="n">squareform</span><span class="p">(</span><span class="n">rbf_dist</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">distArray</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">partition_3</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mahalanobis distance that assigns different weights to the features</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">Dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;mahalanobis&quot;</span><span class="p">,</span> <span class="n">VI</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">weights</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Compute the partition</span>
<span class="n">distArray</span> <span class="o">=</span> <span class="n">ssd</span><span class="o">.</span><span class="n">squareform</span><span class="p">(</span><span class="n">Dist</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">distArray</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">partition_4</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;RBF-based distance&quot;</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="n">partition_3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_clusters</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Weighted Mahalanobis distance&quot;</span><span class="p">,</span> <span class="n">clusters</span><span class="o">=</span><span class="n">partition_4</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/aa95acd20c8548a56be9a91dface1b67ed0bb8e3c80b8232042bbfb988710cbc.png" src="../../_images/aa95acd20c8548a56be9a91dface1b67ed0bb8e3c80b8232042bbfb988710cbc.png" />
</div>
</div>
<ul class="simple">
<li><p>It should be clear by now the impact of the (dis)similarity measure in classification and clustering.</p></li>
<li><p>But how to measure the distance between time series?</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="time-series-similarity">
<h2>Time series similarity<a class="headerlink" href="#time-series-similarity" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>We will look at 3 families of approaches to compute a distance between time series:</p>
<ul>
<li><p>Alignment-based metrics.</p></li>
<li><p>Time series kernels.</p></li>
<li><p>Vector distance on time series embeddings.</p></li>
</ul>
</li>
<li><p>Each approach comes with pros and cons.</p></li>
<li><p>In the following, we will look at one representative for each faimily.</p></li>
</ul>
<section id="multivariate-time-series-mts">
<h3>Multivariate Time Series (MTS)<a class="headerlink" href="#multivariate-time-series-mts" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The approaches we discuss in the following can be applied to datasets of MTS.</p></li>
<li><p>An MTS is represented by a matrix <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{T \times V}\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps and <span class="math notranslate nohighlight">\(V\)</span> is the variables.</p></li>
<li><p>The whole datatset can be represented by a 3-dimensional array <code class="docutils literal notranslate"><span class="pre">X</span></code> of size <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">V]</span></code>.</p></li>
<li><p>In a classification setting, the <span class="math notranslate nohighlight">\(i\)</span>-th MTS <code class="docutils literal notranslate"><span class="pre">X[i,:,:]</span></code> is associated with with a class label <code class="docutils literal notranslate"><span class="pre">y[i]</span></code>.</p></li>
</ul>
<img alt="../../_images/mts_data.png" src="../../_images/mts_data.png" />
<p><strong>Example:</strong></p>
<ul class="simple">
<li><p>Consider the <a class="reference external" href="https://ieeexplore.ieee.org/document/4912759">uWave</a> MTS dataset.</p></li>
<li><p>Each MTS represents the <span class="math notranslate nohighlight">\((x,y,z)\)</span> measurements of an accelerometer wore when doing one of the following gestures.</p></li>
<li><p>The dot is the starting point, the arrow the end point.</p></li>
</ul>
<img alt="../../_images/UWaveGestureLibrary.jpg" src="../../_images/UWaveGestureLibrary.jpg" />
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_uwave</span><span class="p">():</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;UWAVE&#39;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;projection&#39;</span><span class="p">:</span> <span class="s1">&#39;3d&#39;</span><span class="p">})</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Y</span><span class="p">))):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">Y</span> <span class="o">==</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="nb">id</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="nb">id</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="nb">id</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_zticks</span><span class="p">(())</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_uwave</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded UWAVE dataset.
Number of classes: 8
Data shapes:
  Xtr: (200, 315, 3)
  Ytr: (200, 1)
  Xte: (428, 315, 3)
  Yte: (428, 1)
</pre></div>
</div>
<img alt="../../_images/2dcbdf5878a7b5d4d7be7320d6d625ff348ff2cc2ab37acd6caeb916e00b05df.png" src="../../_images/2dcbdf5878a7b5d4d7be7320d6d625ff348ff2cc2ab37acd6caeb916e00b05df.png" />
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="alignment-based-metric-dynamic-time-warping-dtw">
<h2>Alignment-based metric – Dynamic Time Warping (DTW)<a class="headerlink" href="#alignment-based-metric-dynamic-time-warping-dtw" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>An alignment-based metric relies on a temporal alignment of two time series to assess their similarity.</p></li>
<li><p>One of the most prominent representatives of this class is Dynamic Time Warping (DTW).</p></li>
<li><p>The idea of DTW is to first align two time series and then compute an Euclidean distance between the matched elements.</p></li>
</ul>
<ul class="simple">
<li><p>Let’s first consider a naïve approach.</p></li>
<li><p>We compute a distance between all the time steps of two time series <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> of length <span class="math notranslate nohighlight">\(T_x\)</span> and <span class="math notranslate nohighlight">\(T_y\)</span>, respectively:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[d(\boldsymbol{x}, \boldsymbol{y}) = \sum \limits_{t=1}^{\min(T_x, T_y)} \|x(t) - y(t)\|_2\]</div>
<ul class="simple">
<li><p>If the two time series are very similar but slightly disaligned, it will produce a large distance.</p></li>
</ul>
<img alt="../../_images/DTW_idea_1.gif" src="../../_images/DTW_idea_1.gif" />
<ul class="simple">
<li><p>DTW disregards the exact timestamps at which the observations occur.</p></li>
<li><p>DTW seeks for the <em>temporal alignment</em> (a matching between time indexes of the two time series) that minimizes Euclidean distance between the aligned series.</p></li>
</ul>
<img alt="../../_images/DTW_idea_2.gif" src="../../_images/DTW_idea_2.gif" />
<section id="dtw-algorithm">
<h3>DTW algorithm<a class="headerlink" href="#dtw-algorithm" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>DTW solves the following optimization problem:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{DTW}(\boldsymbol{x}, \boldsymbol{y}) = \min \limits_{\pi \in \mathcal{P}(\boldsymbol{x}, \boldsymbol{y})} \left( \sum \limits_{(i,j) \in \pi} d(x(i), y(j))  \right)\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi\)</span> is an <em>alignment path</em> of length <span class="math notranslate nohighlight">\(K\)</span>, i.e., a sequence of index pairs.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{P}(\boldsymbol{x}, \boldsymbol{y})\)</span> is the set of all admissible paths.</p></li>
</ul>
<p>An admissible path should satisfy the following conditions:</p>
<ol class="arabic simple">
<li><p>The beginning and the end of the two time series are matched together.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi_{0} = (1,1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\pi_{K-1} = (T_x, T_y)\)</span></p></li>
</ul>
</li>
</ol>
<img alt="../../_images/start_end.png" src="../../_images/start_end.png" />
<ol class="arabic simple" start="2">
<li><p>The sequence is monotonically increasing in both <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> and all time series indexes should appear at least once.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(i_{k-1} \leq i_k \leq i_{k-1}+1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(j_{k-1} \leq j_k \leq j_{k-1}+1\)</span></p></li>
</ul>
</li>
</ol>
<img alt="../../_images/conditions.png" src="../../_images/conditions.png" />
<ul class="simple">
<li><p>The DTW path can be represented by a binary matrix <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> whose non-zero entries are those corresponding to a matching between time series elements:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}(\mathbf{P}_\pi)_{i,j} = \begin{cases}1 &amp;= \text{if}\; (i,j)\in \pi \\ 0 &amp;= \text{otherwise}\end{cases}\end{split}\]</div>
<ul class="simple">
<li><p>Using the matrix notation, DTW can be rewritten as</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\text{DTW}(\boldsymbol{x}, \boldsymbol{y}) = \min \limits_{\pi \in \mathcal{P}(\boldsymbol{x}, \boldsymbol{y})} \langle \mathbf{P}_\pi, \mathbf{D}_{\boldsymbol{x}, \boldsymbol{y}} \rangle\]</div>
<ul class="simple">
<li><p>where the <span class="math notranslate nohighlight">\((i,j)^{th}\)</span> element of <span class="math notranslate nohighlight">\(\mathbf{D}_{\boldsymbol{x}, \boldsymbol{y}} \in \mathbb{R}^{T_x \times T_y}\)</span> stores the distance <span class="math notranslate nohighlight">\(d(x(i), y(j))\)</span>.</p></li>
</ul>
<img alt="../../_images/matrix.png" src="../../_images/matrix.png" />
<section id="finding-the-optimal-path">
<h4>Finding the optimal path<a class="headerlink" href="#finding-the-optimal-path" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>First, we fill-up the cost matrix <span class="math notranslate nohighlight">\(\mathbf{D}_{\boldsymbol{x}, \boldsymbol{y}}\)</span>.</p></li>
</ul>
<img alt="../../_images/cost.gif" src="../../_images/cost.gif" />
<ul class="simple">
<li><p>Then, we start traversing the matrix from the top-left corner <span class="math notranslate nohighlight">\((0,0)\)</span> to the bottom-right one <span class="math notranslate nohighlight">\((T_x, T_y)\)</span>.</p></li>
<li><p>Excluding the borders, at each step we have three options to decide where to go.</p></li>
<li><p>Each path results in a different cost.</p></li>
<li><p>The optimal path is the one with minimum cost… 🤔 But how to find it?</p></li>
</ul>
<img alt="../../_images/path.gif" src="../../_images/path.gif" />
<ul class="simple">
<li><p>We need to compute the cost for each possible path.</p></li>
<li><p>When <span class="math notranslate nohighlight">\(T_x=T_y\)</span>, the total number of paths is <span class="math notranslate nohighlight">\(\mathcal{O}\left(\frac{(3+2\sqrt{2})^{T_x}}{\sqrt{T_x}}\right)\)</span>.</p></li>
<li><p>That is a big number: looking at all of them is intractable.</p></li>
</ul>
<ul class="simple">
<li><p>There are many paths share the same sections.</p></li>
<li><p>To make the problem tractable, we must avoid recomputing the same paths over and over.</p></li>
</ul>
<img alt="../../_images/redundant.png" src="../../_images/redundant.png" />
<ul class="simple">
<li><p>We can use <em>recursion</em>, a dynamic programming technique that breaks down a complex problem into simpler subproblems.</p></li>
<li><p>Each subproblem is solved just once and the solution is stored in memory.</p></li>
<li><p>When a subproblem is encountered again, its solution is retrieved instead of being recomputed.</p></li>
<li><p>This significantly reduces the number of computations cutting the redundancies.</p></li>
</ul>
<ul class="simple">
<li><p>The recursive algorithm has complexity <span class="math notranslate nohighlight">\(\mathcal{O}(T_x T_y)\)</span> and is formulated as follow:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">DTWDistance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
      <span class="n">DTW</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">DTW</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">min</span><span class="p">(</span>
          <span class="n">DTW</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span>  <span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span>             <span class="k">else</span> <span class="n">inf</span><span class="p">,</span>
          <span class="n">DTW</span><span class="p">[</span><span class="n">i</span>  <span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span>             <span class="k">else</span> <span class="n">inf</span><span class="p">,</span>
          <span class="n">DTW</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="k">else</span> <span class="n">inf</span>
        <span class="p">)</span>
  <span class="k">return</span> <span class="n">DTW</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The idea is that each block <span class="math notranslate nohighlight">\((i,j)\)</span> recursively ask to its predecessors <span class="math notranslate nohighlight">\((i-1, j)\)</span>, <span class="math notranslate nohighlight">\((i, j-1)\)</span>, and <span class="math notranslate nohighlight">\((i-1, j-1)\)</span> the cost to reach them.</p></li>
<li><p>The request is propagated back to the origin <span class="math notranslate nohighlight">\((0,0)\)</span> wich returns the first answer.</p></li>
<li><p>The answer is then propagated forward to all the requesters, which update the answer with their own cost.</p></li>
</ul>
<img alt="../../_images/recursion.gif" src="../../_images/recursion.gif" />
</section>
<section id="dtw-properties">
<h4>DTW properties<a class="headerlink" href="#dtw-properties" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The example below show how the DTW changes when two curves are translated and stretched/squeezed at the same time.</p></li>
</ul>
<img alt="../../_images/warping.gif" src="../../_images/warping.gif" />
<ul class="simple">
<li><p>Note that the distance influenced only by the “stretching/squeezing” part.</p></li>
<li><p>In fact, the DTW is invariant to translation.</p></li>
</ul>
<img alt="../../_images/warping_fix.gif" src="../../_images/warping_fix.gif" />
<ul class="simple">
<li><p>Note that is possible to add constraints that generate a cost if translation exceeds a certain limit.</p></li>
</ul>
<img alt="../../_images/warping_constrained.gif" src="../../_images/warping_constrained.gif" />
</section>
<section id="dtw-example">
<h4>DTW example<a class="headerlink" href="#dtw-example" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Let’s see DTW in action starting with a simple example.</p></li>
<li><p>We generate two groups of time series using two different AR(1) processes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Length of the time series</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">30</span>  <span class="c1"># Time series per set</span>

<span class="c1"># Generate the first set of time series</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">Y1</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">arma_generate_sample</span><span class="p">(</span><span class="n">ar</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">.9</span><span class="p">],</span> <span class="n">ma</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nsample</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 

<span class="c1"># Generate the second set of time series</span>
<span class="n">Y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">Y2</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">arma_generate_sample</span><span class="p">(</span><span class="n">ar</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">.9</span><span class="p">],</span> <span class="n">ma</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nsample</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s visualize how the two groups look like by plotting the mean and std of each set</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;First set&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Y2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Second set&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/43fa76dc1039223cfe6c2bd5a92b94dd0a4e67f466e317ff49aed5636257be86.png" src="../../_images/43fa76dc1039223cfe6c2bd5a92b94dd0a4e67f466e317ff49aed5636257be86.png" />
</div>
</div>
<ul class="simple">
<li><p>Next, we visualize the path <span class="math notranslate nohighlight">\(\pi\)</span> on the cost matrix <span class="math notranslate nohighlight">\(\mathbf{D}_{\boldsymbol{x}, \boldsymbol{y}}\)</span> for the time series we generated.</p></li>
<li><p>First, we let <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> be two time series from the same group.</p></li>
<li><p>Notice how the path <span class="math notranslate nohighlight">\(\pi\)</span> crosses the darker areas, corresponding to smaller dissimilarity values.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1</span> <span class="o">=</span> <span class="n">Y2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">Y2</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">d</span><span class="p">,</span> <span class="n">paths</span> <span class="o">=</span> <span class="n">dtw</span><span class="o">.</span><span class="n">warping_paths</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)</span>
<span class="n">best_path</span> <span class="o">=</span> <span class="n">dtw</span><span class="o">.</span><span class="n">best_path</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
<span class="n">dtwvis</span><span class="o">.</span><span class="n">plot_warpingpaths</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">paths</span><span class="p">,</span> <span class="n">best_path</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/3d01b8bb99c1848d0e3294425b819a35600834daaa47e8e0c78ade247e37e400.png" src="../../_images/3d01b8bb99c1848d0e3294425b819a35600834daaa47e8e0c78ade247e37e400.png" />
</div>
</div>
<ul class="simple">
<li><p>Then, we select <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> from two different groups.</p></li>
<li><p>We see how the dissimilarity is much higher in this case and the path <span class="math notranslate nohighlight">\(\pi\)</span> changes significantly.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1</span> <span class="o">=</span> <span class="n">Y1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">Y2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">d</span><span class="p">,</span> <span class="n">paths</span> <span class="o">=</span> <span class="n">dtw</span><span class="o">.</span><span class="n">warping_paths</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)</span>
<span class="n">best_path</span> <span class="o">=</span> <span class="n">dtw</span><span class="o">.</span><span class="n">best_path</span><span class="p">(</span><span class="n">paths</span><span class="p">)</span>
<span class="n">dtwvis</span><span class="o">.</span><span class="n">plot_warpingpaths</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">paths</span><span class="p">,</span> <span class="n">best_path</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b416e41b2f5854b3f8f66ab67e9c6e46ede57786771a636f099f431f023ed4ff.png" src="../../_images/b416e41b2f5854b3f8f66ab67e9c6e46ede57786771a636f099f431f023ed4ff.png" />
</div>
</div>
<ul class="simple">
<li><p>Finally, we compute the DTW distance between all the time series in the two sets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Concatenate the two sets of time series</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Y2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Compute the distance matrix</span>
<span class="n">dtw_dist</span> <span class="o">=</span> <span class="n">dtw</span><span class="o">.</span><span class="n">distance_matrix_fast</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># Plot the distance matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dtw_dist</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/344cc3c49165ba4b3bfb20caf8fcf5f1adee3e84d65b667f420ce47df0e54a69.png" src="../../_images/344cc3c49165ba4b3bfb20caf8fcf5f1adee3e84d65b667f420ce47df0e54a69.png" />
</div>
</div>
<ul class="simple">
<li><p>We see a clear block structure.</p></li>
<li><p>The dissimilarity is lower between time series of the same group.</p></li>
</ul>
<ul class="simple">
<li><p>For comparison, we also compute the Euclidean distance between the time series.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute euclidean distance between the time series</span>
<span class="n">euc_dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">euc_dist</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/cdfa621fd547519eb971c570787b348faf62f8715194f0ec2f47894990929657.png" src="../../_images/cdfa621fd547519eb971c570787b348faf62f8715194f0ec2f47894990929657.png" />
</div>
</div>
<ul class="simple">
<li><p>This time the dissimilarity matrix is much less structured and is harder to see the division in two groups.</p></li>
<li><p>As expected, the Euclidean distance is less suitable for these type of data.</p></li>
</ul>
</section>
</section>
<section id="classification-with-dtw">
<h3>Classification with DTW<a class="headerlink" href="#classification-with-dtw" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Now we turn to a real classification problem.</p></li>
<li><p>We will use one of the following datasets.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">available_datasets</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Available datasets:

AtrialFibrillation
ArabicDigits
Auslan
CharacterTrajectories
CMUsubject16
ECG2D
Japanese_Vowels
KickvsPunch
Libras
NetFlow
RobotArm
UWAVE
Wafer
Chlorine
Phalanx
SwedishLeaf
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Japanese_Vowels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Japanese_Vowels dataset.
Number of classes: 9
Data shapes:
  Xtr: (270, 29, 12)
  Ytr: (270, 1)
  Xte: (370, 29, 12)
  Yte: (370, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Concatenate X and Xte</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Ytr</span><span class="p">,</span> <span class="n">Yte</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the dissimilarity matrix</span>
<span class="n">dtw_dist</span> <span class="o">=</span> <span class="n">dtw_ndim</span><span class="o">.</span><span class="n">distance_matrix_fast</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dist shape:&quot;</span><span class="p">,</span> <span class="n">dtw_dist</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dist shape: (640, 640)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Note that we have concatenated the training and test set before computing the distances. Why?</p></li>
<li><p>In the following, we will use an SVC with a pre-computed kernel, i.e., a custom similarity matrix (more details <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#custom-kernels">here</a>).</p></li>
<li><p>There are two sets of distances we need to compute to provide the information to the classifier.</p></li>
</ul>
<ul class="simple">
<li><p>For training, we need the distances between elements in the training set.</p>
<ul>
<li><p>Let’s call the matrix containing these distances <strong>tr-tr</strong>.</p></li>
</ul>
</li>
<li><p>For testing, we need the distances between the training and test set elements.</p>
<ul>
<li><p>These distances are in the matrix <strong>te-tr</strong>.</p></li>
</ul>
</li>
</ul>
<img alt="../../_images/dist_matrix.png" src="../../_images/dist_matrix.png" />
<ul class="simple">
<li><p>Unfortunately, <code class="docutils literal notranslate"><span class="pre">dtw_ndim.distance_matrix_fast</span></code> does not compute distances across two different sets, meaning that it cannot compute <strong>te-tr</strong> explicitly.</p></li>
<li><p>In our case, since the dataset is small, we can compute the whole distance matrix and keep only the parts we need.</p></li>
<li><p>Note that some computations (<strong>tr-te</strong> and <strong>te-te</strong>) are <em>wasted</em>.</p></li>
<li><p>If the computing resources are limited or the dataset is too large, it’s better to iterate through the elements of the training and test set and compute only the distances that we actually need.</p></li>
</ul>
<ul class="simple">
<li><p>The kernel is a similarity matrix with elements in [0,1].</p></li>
<li><p>We can obtain it with the following transformation.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtw_sim</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">dtw_dist</span><span class="o">/</span><span class="n">dtw_dist</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="c1"># Plot the similarity matrix</span>
<span class="n">idx_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dtw_sim_sorted</span> <span class="o">=</span> <span class="n">dtw_sim</span><span class="p">[:,</span><span class="n">idx_sorted</span><span class="p">][</span><span class="n">idx_sorted</span><span class="p">,:]</span>
<span class="n">fig</span> <span class="o">=</span>  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dtw_sim_sorted</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/bcc61d0a8a498acabf49326b7bf7a2655c50543af58ff5c0cecffebfbc0525e1.png" src="../../_images/bcc61d0a8a498acabf49326b7bf7a2655c50543af58ff5c0cecffebfbc0525e1.png" />
</div>
</div>
<ul class="simple">
<li><p>Next, we extract the kernels that we actually need.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sim_trtr</span> <span class="o">=</span> <span class="n">dtw_sim</span><span class="p">[:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sim_trtr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">sim_tetr</span> <span class="o">=</span> <span class="n">dtw_sim</span><span class="p">[</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sim_tetr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(270, 270)
(370, 270)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Finally we train the classifier and compute the classification performance on the test data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sim_trtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sim_tetr</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Yte</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 97.30%
</pre></div>
</div>
</div>
</div>
<section id="k-nn-classifier">
<h4><span class="math notranslate nohighlight">\(k\)</span>-NN classifier<a class="headerlink" href="#k-nn-classifier" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Once computed, the distance/similarity matrix can seamlessly be used with other classifiers.</p></li>
<li><p>One example is the classic the <span class="math notranslate nohighlight">\(k\)</span>-NN classifier, which simply implements a majority vote:</p>
<ul>
<li><p>A test sample is assigned the most frequent class among its <span class="math notranslate nohighlight">\(k\)</span> nearest neighbors (<span class="math notranslate nohighlight">\(k\)</span>-NN) in the training set.</p></li>
</ul>
</li>
<li><p>In our case, the <span class="math notranslate nohighlight">\(k\)</span>-NN are identified based on the DTW distance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># In this case we use the DTW distance directly.</span>
<span class="n">dtw_trtr</span> <span class="o">=</span> <span class="n">dtw_dist</span><span class="p">[:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">dtw_tetr</span> <span class="o">=</span> <span class="n">dtw_dist</span><span class="p">[</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span> <span class="c1"># specify k=3</span>
<span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dtw_trtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtw_tetr</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Yte</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 96.49%
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="clustering-with-dtw">
<h3>Clustering with DTW<a class="headerlink" href="#clustering-with-dtw" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>To perform clustering we can use HC.</p></li>
<li><p>As before, we will use Ward Linkage to generate the hierarchy <code class="docutils literal notranslate"><span class="pre">Z</span></code>.</p></li>
<li><p>We need to pass the DTW dissimilarity matrix.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">distArray</span> <span class="o">=</span> <span class="n">ssd</span><span class="o">.</span><span class="n">squareform</span><span class="p">(</span><span class="n">dtw_dist</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">distArray</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>To obtain the acutal clusters we need to put a threshold.</p></li>
<li><p>To select the threshold, we look at the hierarchy <code class="docutils literal notranslate"><span class="pre">Z</span></code> with a dendrogram plot.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">above_threshold_color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> 
                <span class="n">show_leaf_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/052c27eeb65836088eae2fac313ebde810edf55b5f6b52f6c21b37911df65663.png" src="../../_images/052c27eeb65836088eae2fac313ebde810edf55b5f6b52f6c21b37911df65663.png" />
</div>
</div>
<ul class="simple">
<li><p>A value between 50 and 60 seems to give a stable partition.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">55</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">partition</span><span class="p">))</span><span class="si">}</span><span class="s2"> clusters&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 9 clusters
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Finally, we compute the agreement between the partition and the actual class labels.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DTW-based clustering NMI: </span><span class="si">{</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DTW-based clustering NMI: 0.95
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualization-through-dimensionality-reduction">
<h3>Visualization through dimensionality reduction<a class="headerlink" href="#visualization-through-dimensionality-reduction" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>How can we visualize our dataset in a meaningful way?</p></li>
<li><p>We have <span class="math notranslate nohighlight">\(N\)</span> and each one is a multivariate time series of size <span class="math notranslate nohighlight">\(T \times V\)</span>.</p></li>
<li><p>Plotting them directly is impossible.</p></li>
</ul>
<ul class="simple">
<li><p>In a previous lecture we encountered PCA, a technique to reduce data to lower dimension.</p></li>
<li><p>Reducing data to 2 or 3 dimension would make visualization possible.</p></li>
</ul>
<ul class="simple">
<li><p>If the data are vectors, i.e., <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times V}\)</span>, PCA first computes the empirical correlation matrix <span class="math notranslate nohighlight">\(\mathbf{X}^\top\mathbf{X} \in \mathbb{R}^{V \times V}\)</span> that captures the variance and covariance among the features of the dataset.</p></li>
<li><p>PCA uses this information to project the data onto the directions (principal components) that maximize variance.</p></li>
<li><p>Unfortunately, the empirical correlation is meaningless if the data are time series because we are not interested in the correlation of individual time steps.</p></li>
<li><p>The problem further complicates if the time series are multivariate.</p></li>
</ul>
<ul class="simple">
<li><p>PCA can compute the principal components also through the eigendecomposition of the Gram matrix <span class="math notranslate nohighlight">\(\mathbf{X}\mathbf{X}^\top \in \mathbb{R}^{N \times N}\)</span>.</p></li>
<li><p>The Gram matrix is a covariance matrix, i.e., a similarity matrix that captures linear relationships in the data.</p></li>
<li><p>As with the Euclidean distance, a linear covariance matrix is not suitable for time series.</p></li>
<li><p>However, we can replace the covariance with another kernel matrix, such as the one derived from DTW.</p></li>
<li><p>The PCA algorithm that uses kernel matrices is called <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/decomposition/plot_kernel_pca.html">KernelPCA</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kpca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span>
<span class="n">embeddings_pca</span> <span class="o">=</span> <span class="n">kpca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">dtw_sim</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span>  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">embeddings_pca</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">embeddings_pca</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;tab20&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Kernel PCA embeddings&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(());</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5a1bae647eafd5a4181268c00dca04de7886488a60ddc62a3b47a4add49e8550.png" src="../../_images/5a1bae647eafd5a4181268c00dca04de7886488a60ddc62a3b47a4add49e8550.png" />
</div>
</div>
<ul class="simple">
<li><p>KernelPCA maps each time series to a 2D point.</p></li>
<li><p>The DTW-based similarity caputures well the structure of the data and the relationships among the time series.</p></li>
<li><p>As a result, in the KernelPCA project the classes are well separated.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="time-series-kernels">
<h2>Time-series kernels<a class="headerlink" href="#time-series-kernels" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A kernel for time series data is a mathematical function used to measure the similarity between two time series</p></li>
</ul>
<div class="math notranslate nohighlight">
\[k(\boldsymbol{x}, \boldsymbol{y}) \geq 0\]</div>
<ul class="simple">
<li><p>We will consider the <a class="reference external" href="https://github.com/FilippoMB/Time-series-cluster-kernel">Time Series Cluster Kernel (TCK)</a>, which offers the following advanages</p>
<ul>
<li><p>Suitable for multi-variate time series.</p></li>
<li><p>Can deal with missing data.</p></li>
<li><p>Robust to hyperparameters selection.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>To build a kernel, TCK combines <em>Gaussian Mixture Models (GMM)</em> with an <em>ensemble learning</em> approach.</p></li>
</ul>
<img alt="../../_images/tck_scheme.png" src="../../_images/tck_scheme.png" />
<section id="gmm">
<h3>GMM<a class="headerlink" href="#gmm" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A GMM assumes that all the data points are generated from a mixture of <span class="math notranslate nohighlight">\(C\)</span> Gaussian distributions (components) with unknown parameters <span class="math notranslate nohighlight">\(\{ \mu_c, \Sigma_c \}_{c=1}^C\)</span>.</p></li>
<li><p>GMMs are used for clustering.</p></li>
<li><p>Each cluster is modeled by a Gaussian distribution.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_gmm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_components</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s2">&quot;full&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Plot data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    
    <span class="c1"># Plot ellipses</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">][:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">v</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">covariances</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="mi">180</span> <span class="o">*</span> <span class="n">angle</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>  <span class="c1"># convert to degrees</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="n">ell</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">patches</span><span class="o">.</span><span class="n">Ellipse</span><span class="p">(</span>
            <span class="n">gmm</span><span class="o">.</span><span class="n">means_</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">angle</span><span class="o">=</span><span class="mi">180</span> <span class="o">+</span> <span class="n">angle</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span>
        <span class="p">)</span>
        <span class="n">ell</span><span class="o">.</span><span class="n">set_clip_box</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">bbox</span><span class="p">)</span>
        <span class="n">ell</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ell</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create toy data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">950</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                                    <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">class_sep</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">flip_y</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]):</span>
    <span class="n">plot_gmm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GMM with $C$=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> components&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/45e1ae67cd786327dfb484463ed245001b5b95bf32b3ce9c4e93138253cad70a.png" src="../../_images/45e1ae67cd786327dfb484463ed245001b5b95bf32b3ce9c4e93138253cad70a.png" />
</div>
</div>
<p>Mathematically, a GMM is defined as:</p>
<div class="math notranslate nohighlight">
\[p(x) = \sum_{c=1}^{C} \pi_c \mathcal{N}(x | \mu_c, \Sigma_c)\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\pi_c\)</span> is the mixing coefficient of the <span class="math notranslate nohighlight">\(c\)</span>-th Gaussian, with <span class="math notranslate nohighlight">\(0 \leq \pi_c \leq 1\)</span> and <span class="math notranslate nohighlight">\(\sum_{c=1}^{C} \pi_c = 1\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\pi_c\)</span> indicates how much data point <span class="math notranslate nohighlight">\(x\)</span> belongs to the <span class="math notranslate nohighlight">\(c\)</span>-th Gaussian <span class="math notranslate nohighlight">\(\mathcal{N}(x | \mu_c, \Sigma_c)\)</span>.</p></li>
</ul>
<ul class="simple">
<li><p>Clustering with GMM involves estimating the parameters <span class="math notranslate nohighlight">\(\pi_c\)</span>, <span class="math notranslate nohighlight">\(\mu_c\)</span>, and <span class="math notranslate nohighlight">\(\Sigma_c\)</span> using the Expectation-Maximization (EM) algorithm:</p>
<ul>
<li><p>The EM algorithm iteratively assigns data points to clusters (expectation step).</p></li>
<li><p>Then, updates the parameters to maximize the likelihood of the data given the clusters (maximization step).</p></li>
</ul>
</li>
<li><p>In the end, each data point is assigned a probability of belonging to each cluster.</p></li>
<li><p>The output is a <em>soft clustering</em> where points can belong to multiple clusters with different probabilities.</p></li>
</ul>
<ul class="simple">
<li><p>The output can be represented by a <em>soft cluster assignment matrix</em> <span class="math notranslate nohighlight">\(\boldsymbol{\Pi} \in \mathbb{R}^{N \times C}\)</span>.</p></li>
<li><p>The <span class="math notranslate nohighlight">\((i,c)\)</span>-th element of <span class="math notranslate nohighlight">\(\boldsymbol{\Pi}\)</span> is the membership of the MTS <span class="math notranslate nohighlight">\(i\)</span> to cluster <span class="math notranslate nohighlight">\(c\)</span>: <span class="math notranslate nohighlight">\(\boldsymbol{\Pi}[i,c] = \pi^{(i)}_c\)</span>.</p></li>
<li><p>The <span class="math notranslate nohighlight">\(i\)</span>-th row of <span class="math notranslate nohighlight">\(\boldsymbol{\Pi}\)</span> represent all the memberships oft the <span class="math notranslate nohighlight">\(i\)</span>-th MTS: <span class="math notranslate nohighlight">\(\boldsymbol{\Pi}[i,:] = \Pi^{(i)}\)</span>.</p></li>
<li><p>Crisp cluster assignments are obtained by taking the maximum value in <span class="math notranslate nohighlight">\(\Pi^{(i)}\)</span>.</p></li>
</ul>
<img alt="../../_images/soft_clust.png" src="../../_images/soft_clust.png" />
</section>
<section id="gmm-for-time-series-with-missing-data">
<h3>GMM for time series with missing data<a class="headerlink" href="#gmm-for-time-series-with-missing-data" title="Link to this heading">#</a></h3>
<p>TCK modifies the standard GMM model in two ways.</p>
<ol class="arabic simple">
<li><p>To handle <em>time series data</em>, the means of the GMM model become multi-variate time series.</p>
<ul class="simple">
<li><p>Standard GMM: <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_c \in \mathbb{R}^V\)</span>.</p></li>
<li><p>TCK GMM: <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_c \in \mathbb{R}^{T \times V}\)</span>.</p></li>
</ul>
</li>
</ol>
<ol class="arabic simple" start="2">
<li><p>To handle missing values, TCK puts priors on the GMM parameters and replaces the EM algorithm with Maximum a-posteriori (MAP) estimation.</p>
<ul class="simple">
<li><p>EM: <span class="math notranslate nohighlight">\(\boldsymbol{\hat \mu},  \boldsymbol{\hat \Sigma} = \text{argmax}_{\boldsymbol{\mu}, \boldsymbol{\Sigma}} p(\mathbf{X} | \boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>.</p></li>
<li><p>MAP with priors: <span class="math notranslate nohighlight">\(\boldsymbol{\hat \mu},  \boldsymbol{\hat \Sigma} = \text{argmax}_{\boldsymbol{\mu}, \boldsymbol{\Sigma}} p(\mathbf{X} | \boldsymbol{\mu}, \boldsymbol{\Sigma}) p(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span></p></li>
</ul>
</li>
</ol>
<ul class="simple">
<li><p>The resulting means are smoother and the parameters are similar to the overall mean and covariance in clusters with few samples.</p></li>
</ul>
<img alt="../../_images/map.png" src="../../_images/map.png" />
<div style="text-align: center; font-size: 15px;">Image: <a href="https://dl.acm.org/doi/abs/10.1145/2110363.2110408">Marlin at al., 2012</a></div><section id="ensemble-learning">
<h4>Ensemble learning<a class="headerlink" href="#ensemble-learning" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Ensemble approach: combine many weak models to obtain a more powerful one.</p></li>
<li><p>Reduces the sensitivity to hyperparameters selection.</p></li>
<li><p>Can produce a well-defined kernel.</p></li>
</ul>
<ul class="simple">
<li><p>The ensemble of GMMs is obtained by fitting <span class="math notranslate nohighlight">\(G\)</span> different GMMs on:</p>
<ul>
<li><p>A subset of the <span class="math notranslate nohighlight">\(N\)</span> MTS in the dataset;</p></li>
<li><p>A subset of the <span class="math notranslate nohighlight">\(V\)</span> variables;</p></li>
<li><p>A segment of indices of length <span class="math notranslate nohighlight">\(\leq T\)</span> in the time series</p></li>
</ul>
</li>
</ul>
<img alt="../../_images/ensemble.png" src="../../_images/ensemble.png" />
<ul class="simple">
<li><p>The kernel matrix is obtained by combining the clustering results from the <span class="math notranslate nohighlight">\(G\)</span> GMMs in the ensemble.</p></li>
<li><p>Specifically, <span class="math notranslate nohighlight">\(k(\boldsymbol{x}, \boldsymbol{y})\)</span> is proportional to how many times <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> are assigned to the same GMM</p></li>
</ul>
<div class="math notranslate nohighlight">
\[k(\boldsymbol{x}, \boldsymbol{y}) = \sum \limits_{g \in G} \Pi^{(\boldsymbol{x})}(g)^\top \Pi^{(\boldsymbol{y})}(g)\]</div>
</section>
</section>
<section id="classification-with-tck">
<h3>Classification with TCK<a class="headerlink" href="#classification-with-tck" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We load the same data as before.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Japanese_Vowels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Japanese_Vowels dataset.
Number of classes: 9
Data shapes:
  Xtr: (270, 29, 12)
  Ytr: (270, 1)
  Xte: (370, 29, 12)
  Yte: (370, 1)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>One of the main advantages of TCK is the ability in handling missing values.</p></li>
<li><p>From the previous data, we randomly remove 40% of the data by setting the values to <code class="docutils literal notranslate"><span class="pre">np.nan</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mask_tr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">Xtr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="n">Xtr</span><span class="p">[</span><span class="n">mask_tr</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="n">mask_te</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="n">Xte</span><span class="p">[</span><span class="n">mask_te</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We create a TCK kernel with <code class="docutils literal notranslate"><span class="pre">G=30</span></code> GMMs, each with <code class="docutils literal notranslate"><span class="pre">C=15</span></code> components.</p>
<ul>
<li><p>In general, the higher the values of <code class="docutils literal notranslate"><span class="pre">G</span></code> the better the performance but the higher the computation time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code> controls the model complexity. Too low <span class="math notranslate nohighlight">\(\rightarrow\)</span> underfit, too high <span class="math notranslate nohighlight">\(\rightarrow\)</span> overfit.</p></li>
</ul>
</li>
<li><p>Then, we fit TCK on the training data.</p></li>
<li><p>As in the DTW case, we compute the two kernels <span class="math notranslate nohighlight">\(K_\text{tr-tr}\)</span> and <span class="math notranslate nohighlight">\(K_\text{tr-te}\)</span> to train and test our classifier.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tck</span> <span class="o">=</span> <span class="n">TCK</span><span class="p">(</span><span class="n">G</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">Ktr</span> <span class="o">=</span> <span class="n">tck</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtr</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;tr-tr&#39;</span><span class="p">)</span>
<span class="n">Kte</span> <span class="o">=</span> <span class="n">tck</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte</span><span class="o">=</span><span class="n">Xte</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;tr-te&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ktr shape: </span><span class="si">{</span><span class="n">Ktr</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">Kte shape: </span><span class="si">{</span><span class="n">Kte</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dataset contains missing data

Training the TCK using the following parameters:
	C = 15, G = 30
	Number of MTS for each GMM: 216 - 270 (80 - 100 percent)
	Number of attributes sampled from [2, 11]
	Length of time segments sampled from [6, 23]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0900a6ab4c4a4a13b970d11c2559b0f3"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "0ecd4990027c4feb8bbe8218b9dac5be"}</script><script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "dc2dc27ba8384e6bb743fcee181d9657"}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ktr shape: (270, 270)
Kte shape: (370, 270)
</pre></div>
</div>
</div>
</div>
<p><strong>💡 Tip</strong></p>
<ul class="simple">
<li><p>If TCK is taking too long, try reducing the number of GMMs (<code class="docutils literal notranslate"><span class="pre">G</span></code>) or the number of components (<code class="docutils literal notranslate"><span class="pre">C</span></code>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Ktr</span><span class="p">,</span> <span class="n">Ytr</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span> <span class="c1"># Train</span>
<span class="n">Ypred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Kte</span><span class="p">)</span> <span class="c1"># Test</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Test accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Yte</span><span class="p">,</span><span class="w"> </span><span class="n">Ypred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Test accuracy: 0.93
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Even with 40% of missing data, with TCK we manage to keep good classification performance.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="time-series-embedding">
<h2>Time-series embedding<a class="headerlink" href="#time-series-embedding" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>The last approach we consider is to embed the whole MTS into a real-valued vector.</p></li>
<li><p>Doing that allows us to use standard (dis)similarity measures for vectorial data (cosine similarity, Euclidean distance, etc…).</p></li>
<li><p>The key problem is how to embed the temporal information into a static vector.</p></li>
</ul>
<ul class="simple">
<li><p>There are many approaches for extracting static features from a time series.</p></li>
<li><p>For example, see <a class="reference external" href="https://github.com/fraunhoferportugal/tsfel">here</a> for a collection of simple techniques.</p></li>
<li><p>In this lecture, we will rely on Reservoir Computing (RC) to generate embeddings of MTS.</p></li>
</ul>
<section id="rc-framework">
<h3>RC framework<a class="headerlink" href="#rc-framework" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We will consider the following <a class="reference external" href="https://reservoir-computing.readthedocs.io/en/latest/">RC framework for MTS classification and clustering</a>.</p></li>
</ul>
<img alt="../../_images/RC_classifier.png" src="../../_images/RC_classifier.png" />
<ul class="simple">
<li><p>The RC framework consists of 4 modules:</p>
<ol class="arabic simple">
<li><p>Reservoir module</p></li>
<li><p>Dimensionality reduction module</p></li>
<li><p>MTS representation module</p></li>
<li><p>Readout module</p></li>
</ol>
</li>
</ul>
<section id="reservoir-module">
<h4>Reservoir module<a class="headerlink" href="#reservoir-module" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>This module generates a sequence of Reservoir states from given an input MTS <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> as</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{h}(t) = \sigma \left(\mathbf{W}_i \boldsymbol{x}(t)+\mathbf{W}_h \mathbf{h}(t-1)\right)\]</div>
<ul class="simple">
<li><p>If we have <span class="math notranslate nohighlight">\(N\)</span> MTS they can be processed in parallel by the Reservoir and generate the sequence of states</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\{\mathbf{H}(1), \mathbf{H}(2), \dots, \mathbf{H}(T)\}\]</div>
<ul class="simple">
<li><p>with <span class="math notranslate nohighlight">\(\mathbf{H}(t) \in \mathbb{R}^{N \times H}\)</span>.</p></li>
<li><p>The Reservoir can operate in two modalities:</p>
<ul>
<li><p>Unidirectional</p></li>
<li><p>Bidirectional</p></li>
</ul>
</li>
</ul>
<p><strong>Unidirectional Reservoir</strong></p>
<ul class="simple">
<li><p>This is the same Reservoir we in the previous lectures.</p>
<ul>
<li><p>Input: MTS data <code class="docutils literal notranslate"><span class="pre">X</span></code> of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">V]</span></code>.</p></li>
<li><p>Output: a sequence of states <code class="docutils literal notranslate"><span class="pre">H</span></code> of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">H]</span></code>.</p></li>
</ul>
</li>
</ul>
<img alt="../../_images/unidir.png" src="../../_images/unidir.png" />
<p><strong>Bidirectional Reservoir</strong></p>
<ul class="simple">
<li><p>This Reservoir process the time series also backwards.</p></li>
<li><p>This allows to retrieve context from both past and future data points capture more complex and longer temporal dependencies.</p></li>
<li><p>a Bidirectional Reservoir is not <em>causal</em>: it cannot be used for forecasting but is suitable for classification and clustering.</p>
<ul>
<li><p>Input: MTS data <code class="docutils literal notranslate"><span class="pre">X</span></code> of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">V]</span></code>.</p></li>
<li><p>Output: a sequence of states <code class="docutils literal notranslate"><span class="pre">H</span></code> of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">T,</span> <span class="pre">2*H]</span></code>.</p></li>
</ul>
</li>
</ul>
<img alt="../../_images/bidir.png" src="../../_images/bidir.png" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Japanese_Vowels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Japanese_Vowels dataset.
Number of classes: 9
Data shapes:
  Xtr: (270, 29, 12)
  Ytr: (270, 1)
  Xte: (370, 29, 12)
  Yte: (370, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">H_uni</span> <span class="o">=</span> <span class="n">Reservoir</span><span class="p">(</span><span class="n">n_internal_units</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span><span class="o">.</span><span class="n">get_states</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">bidir</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unidir</span><span class="se">\n</span><span class="s2">  H: </span><span class="si">{</span><span class="n">H_uni</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">H_bi</span> <span class="o">=</span> <span class="n">Reservoir</span><span class="p">(</span><span class="n">n_internal_units</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span><span class="o">.</span><span class="n">get_states</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">bidir</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bidir</span><span class="se">\n</span><span class="s2">  H: </span><span class="si">{</span><span class="n">H_bi</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unidir
  H: (270, 29, 300)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Bidir
  H: (270, 29, 600)
</pre></div>
</div>
</div>
</div>
</section>
<section id="dimensionality-reduction-module-optional">
<h4>Dimensionality reduction module (optional)<a class="headerlink" href="#dimensionality-reduction-module-optional" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>This module reduces the dimensionality of the Reservor states from <code class="docutils literal notranslate"><span class="pre">[N,T,H]</span></code> (or <code class="docutils literal notranslate"><span class="pre">[N,T,2*H]</span></code>) to <code class="docutils literal notranslate"><span class="pre">[N,T,R]</span></code>.</p></li>
<li><p>This module is optional, i.e., dimensionality reduction can be skipped.</p></li>
<li><p>However, it drammatically speed up computations especially when using more advanced representations (more details soon).</p></li>
<li><p>Dimensionality reduction be be implemented by</p>
<ul>
<li><p>Standard PCA</p></li>
<li><p>Tensor PCA</p></li>
</ul>
</li>
</ul>
<img alt="../../_images/dim_red.png" src="../../_images/dim_red.png" />
<p><strong>Standard PCA</strong></p>
<ul class="simple">
<li><p>Standard PCA only works on uni-dimensional data.</p></li>
<li><p>Reshape <code class="docutils literal notranslate"><span class="pre">H</span></code> from <code class="docutils literal notranslate"><span class="pre">[N,T,H]</span></code> to <code class="docutils literal notranslate"><span class="pre">[N*T,H]</span></code>.</p></li>
<li><p>Apply PCA and keep the first <code class="docutils literal notranslate"><span class="pre">R</span></code> components.</p></li>
<li><p>Reshape <code class="docutils literal notranslate"><span class="pre">[N*T,R]</span></code> back to <code class="docutils literal notranslate"><span class="pre">[N,T,R]</span></code>.</p></li>
<li><p>🛑 Problem: the sample and the time steps are mixed up and modes of variation in time within individual samples are ingored.</p></li>
</ul>
<p><strong>Tensor PCA</strong></p>
<ul class="simple">
<li><p>Compute the following covariance matrix</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{S} = \frac{1}{N-1} \sum \limits_{n=1}^N (\mathbf{H}_n - \mathbf{\bar H})^\top (\mathbf{H}_n - \mathbf{\bar H}) \in \mathbb{R}^{H \times H}\]</div>
<ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(\mathbf{H}_n \in \mathbb{R}^{T \times H}\)</span> is obtained as <code class="docutils literal notranslate"><span class="pre">H[n,:,:]</span></code> and <span class="math notranslate nohighlight">\(\mathbf{\bar H} = \frac{1}{N} \sum \limits_{n=1}^N \mathbf{H}_n \in \mathbb{R}^{T \times H}\)</span>.</p></li>
<li><p>This allows to compute the variations across the Reservoir dimension by keeping sample- and time-dimension separated.</p></li>
<li><p>Take the first <span class="math notranslate nohighlight">\(R\)</span> eigenvectors of <span class="math notranslate nohighlight">\(\mathbf{S}\)</span>: <span class="math notranslate nohighlight">\(\mathbf{D} = [\mathbf{u}_1, \mathbf{u}_2, \dots, \mathbf{u}_R]\in \mathbb{R}^{H \times R}\)</span>.</p></li>
<li><p>Obtain the reduced states with the following matrix multiplication: <span class="math notranslate nohighlight">\(\mathbf{\hat H}_n = \mathbf{H}_n \mathbf{D}\)</span>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">H_red</span> <span class="o">=</span> <span class="n">tensorPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">75</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">H_bi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;H_red: </span><span class="si">{</span><span class="n">H_red</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>H_red: (270, 29, 75)
</pre></div>
</div>
</div>
</div>
</section>
<section id="representation-module">
<h4>Representation module<a class="headerlink" href="#representation-module" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>This module is responsible of transforming the sequence of Reservoir states into a vectorial representation <span class="math notranslate nohighlight">\(\mathbf{r}_\mathbf{X}\)</span>.</p></li>
<li><p>The Reservoir extracts and separates the dynamical features.</p></li>
<li><p>In addition, it keeps a memory of all the past input.</p></li>
<li><p>Therefore, in some cases, is sufficient to keep only the <em>last Reservoir state</em> to represent the whole MTS.</p></li>
</ul>
<img alt="../../_images/last_state.png" src="../../_images/last_state.png" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rx_last</span> <span class="o">=</span> <span class="n">H_red</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rx_last: </span><span class="si">{</span><span class="n">rx_last</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rx_last: (270, 75)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>In practice, even when using a bidirectional Reservoir, this simple representation might fail to capture important information in the middle of the time series.</p></li>
</ul>
<p><strong>Output model space</strong></p>
<p>A more effective representation is obtained as follows.</p>
<ol class="arabic simple">
<li><p>Train a linear readout to predict the MTS one step-ahead</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\boldsymbol{x}(t+1) =  \mathbf{h}(t)\mathbf{W}_o + \mathbf{w}_o\]</div>
<ol class="arabic simple" start="2">
<li><p>The parameters of the linear model <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_o = [\text{vec}(\mathbf{W}_o); \mathbf{w}_o] \in \mathbb{R}^{V(R+1)}\)</span> become the <span class="math notranslate nohighlight">\(\mathbf{r}_\mathbf{X}\)</span>.</p></li>
</ol>
<img alt="../../_images/output_ms.png" src="../../_images/output_ms.png" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out_pred</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># If we use a bidirectional Reservoir we also need to predict the time series backwards</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xtr</span><span class="p">[:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>         

<span class="n">coeff</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">out_pred</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">H_red</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:])</span>
    <span class="n">coeff</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_pred</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
    <span class="n">biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_pred</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="n">rx_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">coeff</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">biases</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rx_out: </span><span class="si">{</span><span class="n">rx_out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># [N, 2*V*(R+1)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rx_out: (270, 1824)
</pre></div>
</div>
</div>
</div>
<p><strong>Reservoir model space</strong></p>
<ul class="simple">
<li><p>A similar approach is to use the coefficients of a linear model that predicts the next state of the Reservoir</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{h}(t+1) =  \mathbf{h}(t)\mathbf{W}_h + \mathbf{w}_h\]</div>
<ul class="simple">
<li><p>The MTS representation <span class="math notranslate nohighlight">\(\mathbf{r}_\mathbf{X}\)</span> becomes <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_h = [\text{vec}(\mathbf{W}_h); \mathbf{w}_h] \in \mathbb{R}^{R(R+1)}\)</span>.</p></li>
</ul>
<img alt="../../_images/reservoir_ms.png" src="../../_images/reservoir_ms.png" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_pred</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">coeff</span><span class="p">,</span> <span class="n">biases</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">H_red</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">res_pred</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">H_red</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">H_red</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:])</span>
    <span class="n">coeff</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_pred</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
    <span class="n">biases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_pred</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="n">rx_res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">coeff</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">biases</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rx_res: </span><span class="si">{</span><span class="n">rx_res</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># [N, R*(R+1)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rx_res: (270, 5700)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>In principle, the Reservoir model space <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_h\)</span> provides a better representation than the Output model space <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_o\)</span>. Why 🤔?</p></li>
</ul>
<ul class="simple">
<li><p>The Reservoir generates a large pool of dynamics but only few are needed to predict the input at a specific forecast horizon, i.e., 1 if we predict <span class="math notranslate nohighlight">\(\boldsymbol{x}(t+1)\)</span>.</p></li>
<li><p>Not being useful for the task, the other dynamics are discarded but they are still useful to characterize the MTS.</p></li>
</ul>
<ul class="simple">
<li><p>On the other hand, to predict the next Reservoir state <span class="math notranslate nohighlight">\(\mathbf{h}(t+1)\)</span> is necessary to consider <em>all</em> Reservoir dynamics.</p></li>
<li><p>This makes <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_h\)</span> a more powerful representation as it fully characterizes the MTS.</p></li>
</ul>
</section>
<section id="readout-module">
<h4>Readout module<a class="headerlink" href="#readout-module" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The readout module is responsible to classify or cluster the MTS representations.</p></li>
<li><p>Being each representation <span class="math notranslate nohighlight">\(\mathbf{r}_\mathbf{X}\)</span> a vector, any standard classifier for vectorial data can be used.</p></li>
<li><p>Similarly, we can use standard (dis)similarity measures for vectorial data.</p></li>
<li><p>For example, clustering can be done using the Linkage aglorithm on the Euclidean distances between MTS representations.</p></li>
</ul>
</section>
</section>
<section id="classification-with-rc-embeddings">
<h3>Classification with RC embeddings<a class="headerlink" href="#classification-with-rc-embeddings" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We can use the high-level function <code class="docutils literal notranslate"><span class="pre">RC_model</span></code> to perform the classification.</p></li>
<li><p>The function takes as input the hyperparameters to configue:</p>
<ol class="arabic simple">
<li><p>the Reservoir module,</p></li>
<li><p>the dimensionality reduction module</p></li>
<li><p>the representation module,</p></li>
<li><p>the readout module.</p></li>
</ol>
</li>
<li><p>To keep things clean, let’s store the hyperparameters in a Python dictionary.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Hyperarameters of the reservoir</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;n_internal_units&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">450</span>        <span class="c1"># size of the reservoir</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;spectral_radius&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>         <span class="c1"># largest eigenvalue of the reservoir</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;leak&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>                   <span class="c1"># amount of leakage in the reservoir state update (None or 1.0 --&gt; no leakage)</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;connectivity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span>           <span class="c1"># percentage of nonzero connections in the reservoir</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;input_scaling&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.1</span>           <span class="c1"># scaling of the input weights</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;noise_level&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.01</span>            <span class="c1"># noise in the reservoir state update</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;n_drop&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>                    <span class="c1"># transient states to be dropped</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;bidir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>                  <span class="c1"># if True, use bidirectional reservoir</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;circle&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>                <span class="c1"># use reservoir with circle topology</span>

<span class="c1"># Dimensionality reduction hyperparameters</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;dimred_method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;tenpca&#39;</span>      <span class="c1"># options: {None (no dimensionality reduction), &#39;pca&#39;, &#39;tenpca&#39;}</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;n_dim&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">75</span>                    <span class="c1"># number of resulting dimensions after the dimensionality reduction procedure</span>

<span class="c1"># Type of MTS representation</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;mts_rep&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;reservoir&#39;</span>         <span class="c1"># MTS representation: {&#39;last&#39;, &#39;mean&#39;, &#39;output&#39;, &#39;reservoir&#39;}</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;w_ridge_embedding&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">10.0</span>      <span class="c1"># regularization parameter of the ridge regression</span>

<span class="c1"># Type of readout</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;readout_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;lin&#39;</span>          <span class="c1"># readout used for classification: {&#39;lin&#39;, &#39;mlp&#39;, &#39;svm&#39;}</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;w_ridge&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">5.0</span>                 <span class="c1"># regularization of the ridge regression readout</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We create a RC classifier by passing the configuration parameters.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span>  <span class="n">RC_model</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We load again the data (good practice to be sure of getting clean data).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Japanese_Vowels&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Japanese_Vowels dataset.
Number of classes: 9
Data shapes:
  Xtr: (270, 29, 12)
  Ytr: (270, 1)
  Xte: (370, 29, 12)
  Yte: (370, 1)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>The RC model expects class labels to be one-hot-encoded, e.g.</p></li>
<li><p><span class="math notranslate nohighlight">\(1 \rightarrow [1, 0, 0, 0 \dots, 0]\)</span>, <span class="math notranslate nohighlight">\(2 \rightarrow [0, 1, 0, 0 \dots, 0]\)</span>, <span class="math notranslate nohighlight">\(3 \rightarrow [0, 0, 1, 0 \dots, 0]\)</span>, etc..</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># One-hot encoding for labels</span>
<span class="n">onehot_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">Ytr</span> <span class="o">=</span> <span class="n">onehot_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Ytr</span><span class="p">)</span>
<span class="n">Yte</span> <span class="o">=</span> <span class="n">onehot_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Yte</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model</span>
<span class="n">tr_time</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training completed in 0.01 min
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute predictions on test data</span>
<span class="n">pred_class</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span> 
<span class="n">accuracy</span><span class="p">,</span> <span class="n">f1</span> <span class="o">=</span> <span class="n">compute_test_scores</span><span class="p">(</span><span class="n">pred_class</span><span class="p">,</span> <span class="n">Yte</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, F1-score = </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy = 0.984, F1-score = 0.984
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Note how this approach is significantly faster than the other we have seen so far.</p></li>
</ul>
</section>
<section id="clustering-with-rc-embeddings">
<h3>Clustering with RC embeddings<a class="headerlink" href="#clustering-with-rc-embeddings" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We will perform the following steps:</p>
<ol class="arabic simple">
<li><p>Generate the vectorial representations for all MTS.</p></li>
<li><p>Compute a dissimilarity matrix.</p></li>
<li><p>Perform clustering with the distance-based HC algotithm Linkage.</p></li>
</ol>
</li>
</ul>
<ul class="simple">
<li><p>Since we are doing clustering, we do not need the train/test split.</p></li>
<li><p>We concatenate the data from both sets together.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Japanese_Vowels&#39;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Ytr</span><span class="p">,</span> <span class="n">Yte</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Japanese_Vowels dataset.
Number of classes: 9
Data shapes:
  Xtr: (270, 29, 12)
  Ytr: (270, 1)
  Xte: (370, 29, 12)
  Yte: (370, 1)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We can re-use the same <code class="docutils literal notranslate"><span class="pre">RC_model</span></code> as before.</p></li>
<li><p>The only difference is that we do not want to apply the readout module.</p></li>
<li><p>Instead, it should return the MTS representations.</p></li>
<li><p>This is achieved by setting <code class="docutils literal notranslate"><span class="pre">'readout_type'</span></code>to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;readout_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># We update this entry from the previous config dict</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the RC model</span>
<span class="n">rcm</span> <span class="o">=</span>  <span class="n">RC_model</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Generate representations of the input MTS</span>
<span class="n">rcm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">mts_representations</span> <span class="o">=</span> <span class="n">rcm</span><span class="o">.</span><span class="n">input_repr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training completed in 0.02 min
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>At this point, we compute the distance matrix using standard metrics for vectorial data.</p></li>
<li><p>For example, we can use the Euclidean or a Cosine distance.</p></li>
<li><p>The latter is often preferred in high-dimensional spaces because Euclidean distance can become inflated and less meaningful (“curse of dimensionality”).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute Dissimilarity matrix</span>
<span class="n">Dist</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">mts_representations</span><span class="p">)</span>
<span class="n">distArray</span> <span class="o">=</span> <span class="n">ssd</span><span class="o">.</span><span class="n">squareform</span><span class="p">(</span><span class="n">Dist</span><span class="p">)</span>

<span class="c1"># Hierarchical clustering</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">distArray</span><span class="p">,</span> <span class="s1">&#39;ward&#39;</span><span class="p">)</span>
<span class="n">clust</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;distance&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">clust</span><span class="p">))</span><span class="si">}</span><span class="s2"> clusters&quot;</span><span class="p">)</span>

<span class="c1"># Evaluate the agreement between class and cluster labels</span>
<span class="n">nmi</span> <span class="o">=</span> <span class="n">v_measure_score</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">clust</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normalized Mutual Information (v-score): </span><span class="si">{</span><span class="n">nmi</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 8 clusters
Normalized Mutual Information (v-score): 0.854
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>What we covered in this lecture.</p>
<ul class="simple">
<li><p>We first introduced the problem of classification and clustering for vectorial data and the importance of choosing a proper measure for computing (dis)similarities among samples.</p></li>
<li><p>Then, we introduced three approaches to compute (dis)similarities across multivariate time series.</p>
<ol class="arabic simple">
<li><p>DTW, an alignment based-metric.</p></li>
<li><p>TCK, a kernel similarity.</p></li>
<li><p>RC embeddings, an approach to embed time series into vectorial data</p></li>
</ol>
</li>
<li><p>These (dis)similarity measures are the cornerstone in time series classification and clustering.</p></li>
<li><p>Once computed, we saw how they can be easily plugged into the same classification and clustering method we saw for vectorial data.</p></li>
</ul>
<p>We conclude by highlighting the main pros and cons of the three approaches to compute MTS (dis)similarity.</p>
<p><strong>DTW</strong></p>
<ul class="simple">
<li><p>✅ In most cases, works well with default hyperparameters.</p></li>
<li><p>✅ Invariant to translations in time.</p></li>
<li><p>❌ Slow</p></li>
<li><p>❌ Does not account for complex dynamical features.</p></li>
</ul>
<p><strong>TCK</strong></p>
<ul class="simple">
<li><p>✅ Hyperparameters are easy to set.</p></li>
<li><p>✅ Handles missing data.</p></li>
<li><p>❌ Very slow.</p></li>
</ul>
<p><strong>RC-embedding</strong></p>
<ul class="simple">
<li><p>✅ Fast.</p></li>
<li><p>✅ Captures complex dynamical features.</p></li>
<li><p>❌ Many hyperparameters to set.</p></li>
</ul>
<ul class="simple">
<li><p>Each approach can achieve better or worse performance depending on the data and the problem at hand.</p></li>
<li><p>Selecting the optimal (dis)similarity measure, classification/clustering algorithm, and hyperparameters is often a difficult procedure.</p></li>
<li><p>It that requires experience and should be performed with systematic approaches such as cross-validation.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p>We will consider the <a class="reference external" href="https://www.timeseriesclassification.com/description.php?Dataset=Libras">Libras</a> dataset. The dataset contains 15 classes of 24 instances each. Each class references to a hand movement type in LIBRAS (Portuguese name ‘LÍngua BRAsileira de Sinais’, oficial brazilian signal language).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Xte</span><span class="p">,</span> <span class="n">Yte</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">()</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;Libras&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loaded Libras dataset.
Number of classes: 15
Data shapes:
  Xtr: (180, 45, 2)
  Ytr: (180, 1)
  Xte: (180, 45, 2)
  Yte: (180, 1)
</pre></div>
</div>
</div>
</div>
<section id="exercise-1">
<h3>Exercise 1<a class="headerlink" href="#exercise-1" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Compute the DTW distance matrix.</p></li>
<li><p>Obtain a similarity matrix from it.</p></li>
<li><p>Plot the two matrices. Comment about the structure you see (remember to sort the elements class-wise).</p></li>
<li><p>Perform classification with SVC and <span class="math notranslate nohighlight">\(k\)</span>-NN classifiers and report:</p>
<ul class="simple">
<li><p>the training and test times,</p></li>
<li><p>the accuracy and the F1 score on the test set.</p></li>
</ul>
</li>
<li><p>Perform hierarchical clustering using the Linkage Ward algorithm.</p></li>
<li><p>Plot a dendrogram and inspect it to select the optimal threshold to generate the clustering partition. Report the NMI for the partition you found.</p></li>
<li><p>Perform dimensionality reduction with KernelPCA. Plot the results in a 2-dimensional plot.</p></li>
</ol>
</section>
<section id="exercise-2">
<h3>Exercise 2<a class="headerlink" href="#exercise-2" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Add 40% of missing values to the training and test data</p></li>
<li><p>Compute the TCK kernel.</p></li>
<li><p>Compute a dissimilarity matrix from the kernel (try to do the complementary of what you did to obtain a similarity from DTW).</p></li>
</ol>
<p>Repeat points 4-7 from the previous exercise.</p>
</section>
<section id="exercise-3">
<h3>Exercise 3<a class="headerlink" href="#exercise-3" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Compute the RC embeddings.</p></li>
<li><p>Obtain a similarity and a dissimilarity matrix from the MTS representations.</p></li>
</ol>
<p>Repeat points 4-7 from the previous exercises.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/12"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../11/nonlinear-ts.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Nonlinear time series analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="../00/resources.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Resources</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-and-clustering">Classification and clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-and-dissimilarity-measures">Similarity and dissimilarity measures</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dissimilarity-measures">Dissimilarity measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#similarity-measures">Similarity measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-and-non-linear-measures">Linear and non-linear measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-classification">Effect on Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-on-clustering">Effect on Clustering</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-similarity">Time series similarity</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-time-series-mts">Multivariate Time Series (MTS)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alignment-based-metric-dynamic-time-warping-dtw">Alignment-based metric – Dynamic Time Warping (DTW)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-algorithm">DTW algorithm</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-the-optimal-path">Finding the optimal path</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-properties">DTW properties</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dtw-example">DTW example</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-dtw">Classification with DTW</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nn-classifier"><span class="math notranslate nohighlight">\(k\)</span>-NN classifier</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-with-dtw">Clustering with DTW</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualization-through-dimensionality-reduction">Visualization through dimensionality reduction</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-kernels">Time-series kernels</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm">GMM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gmm-for-time-series-with-missing-data">GMM for time series with missing data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">Ensemble learning</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-tck">Classification with TCK</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-embedding">Time-series embedding</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rc-framework">RC framework</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reservoir-module">Reservoir module</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-module-optional">Dimensionality reduction module (optional)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#representation-module">Representation module</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#readout-module">Readout module</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-rc-embeddings">Classification with RC embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-with-rc-embeddings">Clustering with RC embeddings</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1">Exercise 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2">Exercise 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3">Exercise 3</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Filippo Maria Bianchi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>